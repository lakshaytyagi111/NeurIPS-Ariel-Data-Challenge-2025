{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":101849,"databundleVersionId":13093295,"sourceType":"competition"},{"sourceId":13660570,"sourceType":"datasetVersion","datasetId":8685254},{"sourceId":13660978,"sourceType":"datasetVersion","datasetId":8685519}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is the first working notebook pipeline for the areal challenge solution","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nimport os\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nprint(\"Imported Libraries Successfully\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:54.698251Z","iopub.execute_input":"2025-11-10T09:28:54.699431Z","iopub.status.idle":"2025-11-10T09:28:56.288608Z","shell.execute_reply.started":"2025-11-10T09:28:54.699342Z","shell.execute_reply":"2025-11-10T09:28:56.287638Z"}},"outputs":[{"name":"stdout","text":"Imported Libraries Successfully\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"VERSION = \"v2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:58.828931Z","iopub.execute_input":"2025-11-10T09:28:58.829445Z","iopub.status.idle":"2025-11-10T09:28:58.834322Z","shell.execute_reply.started":"2025-11-10T09:28:58.829417Z","shell.execute_reply":"2025-11-10T09:28:58.832945Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# import os\n\n# !ls -lh /kaggle/working\n\n# import shutil\n\n# # Compress your .npy file\n# shutil.make_archive('/kaggle/working/signal_v2', 'zip', '/kaggle/working', 'signal_v2.npy')\n\n# from IPython.display import FileLink\n# FileLink('/kaggle/input/ariel-data-challenge-2025/train/1024292144/AIRS-CH0_signal_0.parquet')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:59:15.546429Z","iopub.execute_input":"2025-11-10T09:59:15.546832Z","iopub.status.idle":"2025-11-10T09:59:15.561672Z","shell.execute_reply.started":"2025-11-10T09:59:15.546803Z","shell.execute_reply":"2025-11-10T09:59:15.560534Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"/kaggle/input/ariel-data-challenge-2025/train/1024292144/AIRS-CH0_signal_0.parquet","text/html":"<a href='/kaggle/input/ariel-data-challenge-2025/train/1024292144/AIRS-CH0_signal_0.parquet' target='_blank'>/kaggle/input/ariel-data-challenge-2025/train/1024292144/AIRS-CH0_signal_0.parquet</a><br>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"%%writefile preprocess.py\n\nimport pandas as pd\nimport numpy as np\nimport multiprocessing as mp\nimport itertools\nimport os\nimport subprocess\nfrom astropy.stats import sigma_clip\nfrom numpy.polynomial import Polynomial\nfrom tqdm import tqdm\nimport torch\nimport torch.nn.functional as F\n\n\nROOT = \"/kaggle/input/ariel-data-challenge-2025/\"\nVERSION = \"v2\"\nA_BINNING = 15\nF_BINNING = 12*15\n\n\ndevice = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device : \", device)\nMODE = os.getenv('PREPROCESS_MODE')\n\n\nsensor_sizes_dict = {\n    \"AIRS-CH0\": [[11250, 32, 356], [32, 356]],\n    \"FGS1\": [[135000, 32, 32], [32, 32]],\n}  # input, mask\n\ncl = 8\ncr = 24\n\n\ndef get_gain_offset():\n    \"\"\"\n    Get the gain and offset for a given planet and sensor\n\n    Unlike last year's challenge, all planets use the same adc_info.\n    We can just hard code it.\n    \"\"\"\n    gain = 0.4369\n    offset = -1000.0\n    return gain, offset\n\n\n\ndef read_data(planet_id, sensor, mode):\n    \"\"\"\n    Read the data for a given planet and sensor\n    \"\"\"\n    # get all noise correction frames and signal\n    signal = pd.read_parquet(\n        f\"{ROOT}/{mode}/{planet_id}/{sensor}_signal_0.parquet\",\n        engine=\"pyarrow\",\n    )\n    dark_frame = pd.read_parquet(\n        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/dark.parquet\",\n        engine=\"pyarrow\",\n    )\n    dead_frame = pd.read_parquet(\n        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/dead.parquet\",\n        engine=\"pyarrow\",\n    )\n    linear_corr_frame = pd.read_parquet(\n        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/linear_corr.parquet\",\n        engine=\"pyarrow\",\n    )\n    flat_frame = pd.read_parquet(\n        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/flat.parquet\",\n        engine=\"pyarrow\",\n    )\n\n    # reshape to sensor shape and cast to float64\n    signal = signal.values.astype(np.float64).reshape(sensor_sizes_dict[sensor][0])[\n        :, cl:cr, :\n    ]\n    dark_frame = dark_frame.values.astype(np.float64).reshape(\n        sensor_sizes_dict[sensor][1]\n    )[cl:cr, :]\n    dead_frame = dead_frame.values.reshape(sensor_sizes_dict[sensor][1])[cl:cr, :]\n    flat_frame = flat_frame.values.astype(np.float64).reshape(\n        sensor_sizes_dict[sensor][1]\n    )[cl:cr, :]\n\n    linear_corr = linear_corr_frame.values.astype(np.float64).reshape(\n        [6] + sensor_sizes_dict[sensor][1]\n    )[:, cl:cr, :]\n\n    return (\n        signal,\n        dark_frame,\n        dead_frame,\n        linear_corr,\n        flat_frame,\n    )\n\n\ndef ADC_convert(signal, gain, offset):\n    \"\"\"\n    Step 1: Analog-to-Digital Conversion (ADC) correction\n\n    The Analog-to-Digital Conversion (adc) is performed by the detector to convert the\n    pixel voltage into an integer number. We revert this operation by using the gain\n    and offset for the calibration files 'train_adc_info.csv'.\n    \"\"\"\n\n    signal /= gain\n    signal += offset\n    return signal\n\n\ndef mask_hot_dead(signal, dead, dark):\n    \"\"\"\n    Step 2: Mask hot/dead pixel\n\n    The dead pixels map is a map of the pixels that do not respond to light and, thus,\n    can't be accounted for any calculation. In all these frames the dead pixels are\n    masked using python masked arrays. The bad pixels are thus masked but left\n    uncorrected. Some methods can be used to correct bad-pixels but this task,\n    if needed, is left to the participants.\n    \"\"\"\n\n    hot = sigma_clip(dark, sigma=5, maxiters=5).mask\n    hot = np.tile(hot, (signal.shape[0], 1, 1))\n    dead = np.tile(dead, (signal.shape[0], 1, 1))\n\n    signal[dead] = np.nan\n    signal[hot] = np.nan\n    return signal\n\n\ndef apply_linear_corr(c, signal):\n    \"\"\"\n    Step 3: linearity Correction\n\n    The non-linearity of the pixels' response can be explained as capacitive leakage\n    on the readout electronics of each pixel during the integration time. The number\n    of electrons in the well is proportional to the number of photons that hit the\n    pixel, with a quantum efficiency coefficient. However, the response of the pixel\n    is not linear with the number of electrons in the well. This effect can be\n    described by a polynomial function of the number of electrons actually in the well.\n    The data is provided with calibration files linear_corr.parquet that are the\n    coefficients of the inverse polynomial function and can be used to correct this\n    non-linearity effect.\n    Using horner's method to evaluate the polynomial\n    \"\"\"\n    assert c.shape[0] == 6  # Ensure the polynomial is of degree 5\n\n    return (\n        (((c[5] * signal + c[4]) * signal + c[3]) * signal + c[2]) * signal + c[1]\n    ) * signal + c[0]\n\n\ndef clean_dark(signal, dark, dt):\n    \"\"\"\n    Step 4: dark current subtraction\n\n    The data provided include calibration for dark current estimation, which can be\n    used to pre-process the observations. Dark current represents a constant signal\n    that accumulates in each pixel during the integration time, independent of the\n    incoming light. To obtain the corrected image, the following conventional approach\n    is applied: The data provided include calibration files such as dark frames or\n    dead pixels' maps. They can be used to pre-process the observations. The dark frame\n    is a map of the detector response to a very short exposure time, to correct for the\n    dark current of the detector.\n\n    image - (dark * dt)\n\n    The corrected image is conventionally obtained via the following: where the dark\n    current map is first corrected for the dead pixel.\n    \"\"\"\n\n    dark = torch.tile(dark, (signal.shape[0], 1, 1))\n    signal -= dark * dt[:, None, None]\n    return signal\n\n\ndef get_cds(signal):\n    \"\"\"\n    Step 5: Get Correlated Double Sampling (CDS)\n\n    The science frames are alternating between the start of the exposure and the end of\n    the exposure. The lecture scheme is a ramp with a double sampling, called\n    Correlated Double Sampling (CDS), the detector is read twice, once at the start\n    of the exposure and once at the end of the exposure. The final CDS is the\n    difference (End of exposure) - (Start of exposure).\n    \"\"\"\n\n    return torch.subtract(signal[1::2, :, :], signal[::2, :, :])\n\n\ndef correct_flat_field(flat, signal):\n    \"\"\"\n    Step 6: Flat Field Correction\n\n    The flat field is a map of the detector response to uniform illumination, to\n    correct for the pixel-to-pixel variations of the detector, for example the\n    different quantum efficiencies of each pixel.\n    \"\"\"\n\n    return signal / flat\n\n\ndef bin_obs(signal, binning):\n    \"\"\"\n    Step 5.1: Bin Observations\n\n    The data provided are binned in the time dimension. The binning is performed by\n    summing the signal over the time dimension.\n    \"\"\"\n\n    cds_binned = torch.zeros(\n        (\n            signal.shape[0] // binning,\n            signal.shape[1],\n            signal.shape[2],\n        ),\n        device=device,\n    )\n    for i in range(signal.shape[0] // binning):\n        cds_binned[i, :, :] = torch.sum(\n            signal[i * binning : (i + 1) * binning, :, :], axis=0\n        )\n    return cds_binned\n\n\ndef nan_interpolation(tensor):\n    # Assume tensor is of shape (batch, height, width)\n    nan_mask = torch.isnan(tensor)\n\n    # Replace NaNs with zero temporarily\n    tensor_filled = torch.where(\n        nan_mask, torch.tensor(0.0, device=tensor.device), tensor\n    )\n\n    # Create a binary mask (0 where NaNs were and 1 elsewhere)\n    ones = torch.ones_like(tensor, device=tensor.device)\n    weight = torch.where(nan_mask, torch.tensor(0.0, device=tensor.device), ones)\n\n    # Perform interpolation by convolving with a kernel\n    # using bilinear interpolation\n    kernel = torch.ones(1, 1, 1, 3, device=tensor.device, dtype=tensor.dtype)\n\n    # Apply padding to the tensor and weight to prevent boundary issues\n    tensor_padded = F.pad(\n        tensor_filled.unsqueeze(1), (1, 1, 0, 0), mode=\"replicate\"\n    ).squeeze(1)\n    weight_padded = F.pad(weight.unsqueeze(1), (1, 1, 0, 0), mode=\"replicate\").squeeze(\n        1\n    )\n\n    # Convolve the filled tensor and the weight mask\n    tensor_conv = F.conv2d(tensor_padded.unsqueeze(1), kernel, stride=1)\n    weight_conv = F.conv2d(weight_padded.unsqueeze(1), kernel, stride=1)\n\n    # Compute interpolated values (normalized by weights)\n    interpolated_tensor = tensor_conv / weight_conv\n\n    # Apply the interpolated values only to the positions of NaNs\n    result = torch.where(nan_mask, interpolated_tensor.squeeze(1), tensor)\n\n    return result\n\n\n\ndef process_planet(planet_id):\n    \"\"\"\n    Process a single planet's data\n    \"\"\"\n    axis_info = pd.read_parquet(ROOT + \"/axis_info.parquet\")\n    dt_airs = axis_info[\"AIRS-CH0-integration_time\"].dropna().values\n\n    for sensor in [\"AIRS-CH0\", \"FGS1\"]:\n        # load all data for this planet and sensor\n        signal, dark_frame, dead_frame, linear_corr, flat_frame = read_data(\n            planet_id, sensor, mode=MODE\n        )\n        gain, offset = get_gain_offset()\n\n        # Step 1: ADC correction\n        signal = ADC_convert(signal, gain, offset)\n\n        # Step 2: Mask hot/dead pixel\n        signal = mask_hot_dead(signal, dead_frame, dark_frame)\n\n        # clip at 0\n        signal = torch.tensor(signal.clip(0)).to(device)    \n        signal = apply_linear_corr(\n            torch.tensor(linear_corr).to(device), signal.clone().detach()\n        )\n\n        if sensor == \"FGS1\":\n            dt = torch.ones(len(signal), device=device) * 0.1\n        elif sensor == \"AIRS-CH0\":\n            dt = torch.tensor(dt_airs).to(device)\n\n        dt[1::2] += 0.1\n\n        signal = clean_dark(signal, torch.tensor(dark_frame).to(device), dt)\n\n        # Step 5: Get Correlated Double Sampling (CDS)\n        signal = get_cds(signal)\n\n        # Step 6: Flat Field Correction\n\n        if sensor == \"AIRS-CH0\":\n            signal = bin_obs(signal, binning=A_BINNING)\n        else:\n            signal = bin_obs(signal, binning=F_BINNING)\n\n        signal = correct_flat_field(torch.tensor(flat_frame).to(device), signal)\n\n        # Step 7: Interpolate NaNs (twice!)\n        signal = nan_interpolation(signal)\n        signal = nan_interpolation(signal)\n\n        if sensor == \"FGS1\":\n            signal = torch.nanmean(signal, axis=[1, 2]).cpu().numpy()\n        elif sensor == \"AIRS-CH0\":\n            signal = torch.nanmean(signal, axis=1).cpu().numpy()\n            \n        # save the processed signal\n        np.save(\n            str(planet_id) + \"_\" + sensor + f\"_signal_{VERSION}.npy\",\n            signal.astype(np.float64),\n        )\n\nif __name__ == \"__main__\":\n    star_info = pd.read_csv(ROOT + f\"/{MODE}_star_info.csv\", index_col=\"planet_id\")\n    planet_ids = [int(x) for x in star_info.index.tolist()]\n\n    # Use up to 4 threads!\n    mp.set_start_method('spawn')\n    with mp.Pool(processes=4) as pool:\n        list(tqdm(pool.imap(process_planet, planet_ids), total=len(planet_ids)))\n\n    \n    signal_train = []\n\n    for planet_id in planet_ids:\n        f_raw = np.load(f\"{planet_id}_FGS1_signal_{VERSION}.npy\")\n        a_raw = np.load(f\"{planet_id}_AIRS-CH0_signal_{VERSION}.npy\")\n\n        # flip a_raw\n        signal = np.concatenate([f_raw[:, None], a_raw[:, ::-1]], axis=1)\n        signal_train.append(signal)\n\n        os.remove(\"/kaggle/working/\" + str(planet_id) + f\"_AIRS-CH0_signal_{VERSION}.npy\")\n        os.remove(\"/kaggle/working/\" + str(planet_id) + f\"_FGS1_signal_{VERSION}.npy\")\n\n    signal_train = np.array(signal_train)\n    np.save(f\"signal_{VERSION}.npy\", signal_train, allow_pickle=False)\n\n    print(\"Processing complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:29:11.881244Z","iopub.execute_input":"2025-11-10T09:29:11.881579Z","iopub.status.idle":"2025-11-10T09:29:11.893645Z","shell.execute_reply.started":"2025-11-10T09:29:11.881555Z","shell.execute_reply":"2025-11-10T09:29:11.892619Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Writing preprocess.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_path = f\"/kaggle/input/signal-v2-1-npy/signal_{VERSION} (1).npy\"\nos.environ[\"PREPROCESS_MODE\"] = \"train\"\n\n# Check if preprocessed data already exists\nif not os.path.exists(data_path):\n    print(\"Preprocessed data not found. Running preprocessing...\")\n\n    # Set environment variable for your script\n    os.environ[\"PREPROCESS_MODE\"] = \"train\"\n\n    # Run the preprocessing script\n    !python preprocess.py\n\n    # (Assuming preprocess.py saves 'signal_{VERSION}.npy')\nelse:\n    print(\"Preprocessed data already exists. Skipping preprocessing.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:30:39.972977Z","iopub.execute_input":"2025-11-10T09:30:39.973326Z","iopub.status.idle":"2025-11-10T09:30:39.982601Z","shell.execute_reply.started":"2025-11-10T09:30:39.973300Z","shell.execute_reply":"2025-11-10T09:30:39.981762Z"}},"outputs":[{"name":"stdout","text":"Preprocessed data already exists. Skipping preprocessing.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"data_train = np.load(f\"/kaggle/input/signal-v2-1-npy/signal_{VERSION} (1).npy\")\ndata_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:29:25.858306Z","iopub.execute_input":"2025-11-10T09:29:25.859219Z","iopub.status.idle":"2025-11-10T09:29:36.419650Z","shell.execute_reply.started":"2025-11-10T09:29:25.859168Z","shell.execute_reply":"2025-11-10T09:29:36.418679Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(1100, 375, 357)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(\"check, done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:29:36.421081Z","iopub.execute_input":"2025-11-10T09:29:36.421441Z","iopub.status.idle":"2025-11-10T09:29:36.427359Z","shell.execute_reply.started":"2025-11-10T09:29:36.421414Z","shell.execute_reply":"2025-11-10T09:29:36.425993Z"}},"outputs":[{"name":"stdout","text":"check, done\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/adc_info.csv')\ntrain_star_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/train_star_info.csv')\n\ntrain_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/train.csv',\n                           index_col='planet_id')\nwavelengths = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/wavelengths.csv')\naxis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2025/axis_info.parquet')","metadata":{"execution":{"iopub.status.busy":"2025-11-10T09:29:42.571128Z","iopub.execute_input":"2025-11-10T09:29:42.571534Z","iopub.status.idle":"2025-11-10T09:29:43.115524Z","shell.execute_reply.started":"2025-11-10T09:29:42.571507Z","shell.execute_reply":"2025-11-10T09:29:43.114715Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.signal import savgol_filter\n\n\nMODEL_VERSION = \"v2\"\nPRE_BINNED_TIME = 15\n\nROOT = \"/kaggle/input/ariel-data-challenge-2025/\"\n\n\n# find transit zones\ndef phase_detector(signal_orig, smooth_window=11):\n    signal = signal_orig.reshape(-1, 1).mean(-1)\n    signal = savgol_filter(signal, smooth_window, 2)  # smooth\n    first_derivative = np.gradient(signal)\n    second_derivative = savgol_filter(np.gradient(savgol_filter(first_derivative, 41, 2)), 41, 2)\n\n    local_min = (np.diff(np.sign(np.diff(second_derivative))) > 0).nonzero()[0] + 1\n    local_max = (np.diff(np.sign(np.diff(second_derivative))) < 0).nonzero()[0] + 1\n    \n    if len(local_min) >= 2:\n        top2_min_indices = local_min[np.argsort(second_derivative[local_min])[:2]]\n    else:\n        top2_min_indices = local_min\n    \n    if len(local_max) >= 2:\n        top2_max_indices = local_max[np.argsort(second_derivative[local_max])[-2:]]\n    else:\n        top2_max_indices = local_max\n    top2_min_indices.sort()\n    top2_max_indices.sort()\n\n    # 4 extrema of the 2nd derivative and 2 of the 1st\n    phase1 = top2_min_indices[0]\n    phase2 = top2_max_indices[0]\n    phase3 = top2_max_indices[1]\n    phase4 = top2_min_indices[1]\n    phase5 = np.argmin(first_derivative)\n    phase6 = np.argmax(first_derivative)\n\n    return phase1, phase2, phase3, phase4, phase5, phase6\n\n\ndef get_breakpoints(x, smooth=19):\n    bp1 = np.zeros(x.shape[0], dtype=np.int32)\n    bp2 = np.zeros(x.shape[0], dtype=np.int32)\n    bp3 = np.zeros(x.shape[0], dtype=np.int32)\n    bp4 = np.zeros(x.shape[0], dtype=np.int32)\n    bp5 = np.zeros(x.shape[0], dtype=np.int32)\n    bp6 = np.zeros(x.shape[0], dtype=np.int32)\n    for i in range(x.shape[0]):\n        signal = x[i]\n        p1, p2, p3, p4, p5, p6 = phase_detector(\n            signal, smooth_window=smooth\n        )\n        bp1[i] = p1\n        bp2[i] = p2\n        bp3[i] = p3\n        bp4[i] = p4\n        bp5[i] = p5\n        bp6[i] = p6\n        \n    return [bp1, bp2, bp3, bp4, bp5, bp6]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:30:02.109679Z","iopub.execute_input":"2025-11-10T09:30:02.110245Z","iopub.status.idle":"2025-11-10T09:30:02.299585Z","shell.execute_reply.started":"2025-11-10T09:30:02.110183Z","shell.execute_reply":"2025-11-10T09:30:02.298738Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%%writefile feature_engineering.py\nfrom scipy.signal import savgol_filter\nimport warnings\nfrom scipy.stats import kurtosis, skew\nfrom scipy.signal import medfilt\nfrom scipy.optimize import curve_fit\nfrom scipy.interpolate import interp1d\nfrom numpy.polynomial import Polynomial\nfrom scipy.optimize import least_squares, minimize\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.ndimage import median_filter\n\n\nwarnings.simplefilter(\"ignore\")\n\nA_BINNING = 15\n\n# threshold values for identifying outliers\nbad_low = 20\nbad_up = 354\n\nbuf = 15  # for lower1, upper1\nbuf1 = 10  # for lower, mid1, mid2, upper\n\n\ndef calculate_weights(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    \"\"\"\n    Calculating weights for averaging based on SNR\n    \"\"\"\n    max_len = a.shape[0] - 1\n    if is_outlier:\n        return np.ones_like(a[0]) / a.shape[-1]\n    else:\n        y_combined = np.concatenate([a[:max(lower - buf1, 1), :], a[min(upper + buf1, max_len):, :]], axis=0)\n        ratio = y_combined.mean(0) / y_combined.std(0)\n        return ratio / ratio.sum()\n\n\ndef calc_for_outliers(a, lower, upper):\n    \"\"\"\n    Estimating transit depth for outlier cases\n    \"\"\"\n    max_len = len(a) - 1\n            \n    if lower + buf < upper - buf:\n        obs = a[lower + buf : upper - buf].mean()\n    else:\n        obs = a[lower : upper].mean()\n\n    if lower - buf >= 10 and max_len - upper - buf >= 10:\n        unobs = (np.median(a[:max(lower - buf, 1)]) + np.median(a[min(upper + buf, max_len):])) / 2\n    elif lower >= max_len - upper:\n        unobs = np.median(a[:max(lower - buf, 1)])\n    else:\n        unobs = np.median(a[min(upper + buf, max_len):])\n\n    arr1 = 1 - (obs / unobs)\n    arr2 = 1 - a[(lower + upper) // 2] / unobs\n\n    return arr1, arr2\n\n\ndef calc_err(x_combined, y_combined, degree):\n    \"\"\"\n    Calculating the error to obtain the optimal polynomial degree\n    \"\"\"\n    max_len = 374 # hardcoded for BINNING=15\n    \n    poly_guess = np.polyfit(x_combined, y_combined, degree)\n    inter = np.polyval(poly_guess, np.arange(max_len + 1))\n    err = mean_squared_error(y_combined, inter[x_combined], squared=False)\n\n    # penalizing rmse, high polynomial degree and small number of points in curve fitting.\n    return err * degree**(1 - len(x_combined) / max_len)\n\n    \ndef calc_depth_and_detrend(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False, unstable=False, fixed_degree=None):\n    \"\"\"\n    Main function for transit depth estimation and detrending\n    \n    Parameters:\n        - a: 1d numpy array of observation points\n        - lower, mid1, mid2, upper, lower1, upper1: transit boundary points\n        - is_outlier: boolean flag indicating if the data point is an outlier\n        - unstable: if True, don't use curve fitting\n        - fixed_degree: if not None, use provided degree; otherwise, find optimal degree\n    \n    Returns:\n        - (arr1, arr2): tuple containing the averaged transit depth and the transit depth at mid-transit\n    \"\"\"\n    max_len = len(a) - 1\n    degree = 3\n    \n    if is_outlier:\n        a /= a.mean()\n        arr1, arr2 = calc_for_outliers(a, lower1, upper1)\n    else:\n        a /= a.mean()\n\n        # region outside the transit\n        x_combined = np.concatenate([np.arange(max(lower - buf1, 1)), np.arange(min(upper + buf1, max_len), max_len + 1)], axis=-1)\n        y_combined = a[x_combined]\n            \n        if fixed_degree is None: # find the optimal degre\n            best_val = 10**100\n            for j in [1, 2, 3, 4, 5]:\n                if calc_err(x_combined, y_combined, j) < best_val:\n                    best_val = calc_err(x_combined, y_combined, j)\n                    degree = j\n        else:\n            degree = fixed_degree\n\n        obs = a[mid1 : mid2]\n        \n        if unstable: # no curve fitting\n            unobs = y_combined.mean()\n        else:\n            poly_guess = np.polyfit(x_combined, y_combined, degree)         \n            inter = np.polyval(poly_guess, np.arange(max_len + 1))\n                \n            a /= inter\n            inter /= inter\n            unobs = inter[mid1 : mid2]\n\n        arr1 = 1 - np.mean(obs / unobs)\n        arr2 = 1 - a[(lower1 + upper1) // 2] / unobs.mean()\n                \n\n    if np.isnan(arr1):\n        arr1 = 0\n    if np.isnan(arr2):\n        arr2 = 0\n        \n    return arr1, arr2\n\n\ndef calc_slope(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    \"\"\"\n    Calculate transit wall steepness as slope between contact points\n    \"\"\"\n    max_len = len(a) - 1\n    \n    if not (lower < mid1 < mid2 < upper) or is_outlier:\n        return 0\n    else:\n        return ((a[mid1] - a[lower]) / (mid1 - lower) - (a[upper] - a[mid2]) / (upper - mid2)) / 2\n\n\ndef calc_slope_2(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    \"\"\"\n    Calculate transit bottom curvature as slope between mid-transit \n    and contact point\n    \"\"\"\n    max_len = len(a) - 1\n    \n    if not (lower < mid1 < mid2 < upper) or is_outlier:\n        return 0\n    else:\n        mid_ind = (mid1 + mid2) // 2\n        if not (mid1 < mid_ind < mid2):\n            return 0\n        return ((a[mid_ind] - a[mid1]) / (mid_ind - mid1) - (a[mid2] - a[mid_ind]) / (mid2 - mid_ind)) / 2\n\n\n# calcluating slopes for unsimmetric cases\ndef calc_slope_2_left(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    max_len = len(a) - 1\n    \n    if not (lower < mid1 < mid2 < upper):\n        return 0\n    else:\n        mid_ind = (mid1 + mid2) // 2\n        if not (mid1 < mid_ind < mid2):\n            return 0\n        return (a[mid_ind] - a[mid1]) / (mid_ind - mid1)\n\n\ndef calc_slope_2_right(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    max_len = len(a) - 1\n    \n    if not (lower < mid1 < mid2 < upper):\n        return 0\n    else:\n        mid_ind = (mid1 + mid2) // 2\n        if not (mid1 < mid_ind < mid2):\n            return 0\n        return (a[mid2] - a[mid_ind]) / (mid2 - mid_ind)\n\n\n# gradient slopes\ndef calc_curv_left(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    if not (lower < mid1 < mid2 < upper) or is_outlier:\n        return 0\n    else:\n        mid_ind = (mid1 + mid2) // 2\n        a = savgol_filter(np.gradient(a), 41, 1)\n        return (a[mid_ind] - a[mid1]) / (mid_ind - mid1)\n\n\ndef calc_curv_right(a, lower, mid1, mid2, upper, lower1, upper1, is_outlier=False):\n    if not (lower < mid1 < mid2 < upper) or is_outlier:\n        return 0\n    else:\n        mid_ind = (mid1 + mid2) // 2\n        a = savgol_filter(np.gradient(a), 41, 1)\n        return (a[mid2] - a[mid_ind]) / (mid2 - mid_ind)\n\n\ndef calc_perc(a, lower, upper, q, is_outlier=False):\n    \"\"\"\n    Calculate the percentile of the transit depth, assumes the input signal is already detrended\n    \"\"\"\n    if is_outlier:\n        return 0\n    return np.quantile(1 - a[lower : upper], q)\n    \n\ndef feature_engineering(star_info, data):\n    \"\"\"\n    Prepares features for training or inference\n    \n    Parameters:\n        - star_info: star metadata DataFrame\n        - data: 3d data array (samples, time, frequencies)\n    \n    Returns:\n        tuple of DataFrame and outliers mask\n    \"\"\"\n    df = pd.DataFrame()\n\n    cut_inf, cut_sup = 36, 318\n    \n    signal = np.concatenate(\n        [data[:, :, 0][:, :, None], data[:, :, cut_inf:cut_sup]], axis=2\n    )\n    max_len = signal.shape[1] - 1\n        \n    lower, mid1, mid2, upper, lower1, upper1 = get_breakpoints(signal[:, :, 1:].mean(-1))\n    boundaries = (lower, mid1, mid2, upper, lower1, upper1) \n\n    # identifying outliers\n    outliers = (np.array(lower1) < bad_low) | (np.array(upper1) > bad_up) | (np.array(lower) < bad_low) | (np.array(upper) > bad_up)\n    for i in range(signal.shape[0]):\n        if not (lower[i] < mid1[i] < mid2[i] < upper[i]):\n            outliers[i] = 1\n    \n    signal_mean_raw = np.zeros(signal.shape[:2])\n    for i in tqdm(range(signal_mean_raw.shape[0])): # weighted averaging along frequency dimension\n        weights = calculate_weights(signal[i, :, 1:], *(b[i] for b in boundaries), outliers[i])\n        signal_mean_raw[i, :] = (signal[i, :, 1:] @ weights.T).T\n\n    signal_mean = savgol_filter(signal_mean_raw, 11, 1)\n\n    # frequency set for precise depth estimation via curve fitting (less robust)\n    good_waves = [1, 6, 11, 16, 21, 26, 31, 36, 41, 51, 61, 71, 76, 81, 86, 91, 96, 101, 106, 111, 121, 131, 141, 151, 161, 171, 196, 201, 206]\n    for i in tqdm(range(len(signal_mean))):\n\n        # filter very bad cases :) (exclude from training, use larger sigma for prediction)\n        df.loc[i, 'very_bad'] = (lower1[i] < bad_low // 2 or upper1[i] > max_len - (max_len - bad_up) // 2)\n        if os.environ[\"PREPROCESS_MODE\"] == 'train' and star_info.loc[i, 'planet_id'] in [2486733311, 2554492145]:\n            df.loc[i, 'very_bad'] = True\n\n\n        # averaged and mid-transit depth estimation\n        fake_avg, fake_mid = calc_depth_and_detrend(signal_mean[i].copy(), *(b[i] for b in boundaries), outliers[i], unstable=True)\n        fake_avg_2, fake_mid_2 = calc_depth_and_detrend(signal_mean[i].copy(), *(b[i] for b in boundaries), outliers[i], fixed_degree=3)\n        df.loc[i, 'average_depth'], df.loc[i, 'mid_depth'] = calc_depth_and_detrend(signal_mean[i], *(b[i] for b in boundaries), outliers[i])\n\n        norm_coef = (1 - df.loc[i, 'average_depth']) / (1 - fake_avg)\n        norm_coef_mid = (1 - df.loc[i, 'mid_depth']) / (1 - fake_mid)\n        norm_coef_2 = (1 - df.loc[i, 'average_depth']) / (1 - fake_avg_2)\n                        \n        fg1_signal = signal[i, :, 0].copy()\n        fg1_signal = savgol_filter(fg1_signal, 11, 1)\n        fg1_slope = savgol_filter(signal[i, :, 0].copy(), 41, 2)\n        _, _ = calc_depth_and_detrend(fg1_slope, *(b[i] for b in boundaries), outliers[i], fixed_degree=3) # for detrending\n        \n        df.loc[i, 'fg1_average_depth'], df.loc[i, 'fg1_mid_depth'] = calc_depth_and_detrend(fg1_signal, *(b[i] for b in boundaries), \n                                                                                            outliers[i], \n                                                                                            fixed_degree=3)\n\n        \n        # transit depth percentiles\n        for q in [0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n            df.loc[i, f'q_1_{q}'] = calc_perc(signal_mean[i], mid1[i], mid2[i], q, outliers[i])\n            df.loc[i, f'q_2_{q}'] = calc_perc(signal_mean[i], lower[i] - buf1, upper[i] + buf1, q, outliers[i])\n            df.loc[i, f'q_3_{q}'] = calc_perc(signal_mean[i], lower[i], upper[i], q, outliers[i]) \n        for q in [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9]:\n            df.loc[i, f'fg1_q_1_{q}'] = calc_perc(fg1_signal, mid1[i], mid2[i], q, outliers[i])\n            df.loc[i, f'fg1_q_2_{q}'] = calc_perc(fg1_signal, lower[i], upper[i], q, outliers[i])\n            df.loc[i, f'fg1_q_3_{q}'] = calc_perc(fg1_signal, lower[i] - buf1, upper[i] + buf1, q, outliers[i])\n\n        \n        # slope features\n        df.loc[i, 'slope'] = calc_slope(signal_mean[i], *(b[i] for b in boundaries), outliers[i])\n        df.loc[i, 'slope_2'] = calc_slope_2(signal_mean[i], *(b[i] for b in boundaries), outliers[i])\n        df.loc[i, 'slope_2_left'] = calc_slope_2_left(signal_mean[i], *(b[i] for b in boundaries), outliers[i])\n        df.loc[i, 'slope_2_right'] = calc_slope_2_right(signal_mean[i], *(b[i] for b in boundaries), outliers[i])\n        df.loc[i, 'slope_g'] = max(0, -df.loc[i, 'slope_2'])**0.5\n                          \n        df.loc[i, 'fg1_slope'] = calc_slope(fg1_slope, *(b[i] for b in boundaries), outliers[i])     \n        df.loc[i, 'fg1_slope_2'] = calc_slope_2(fg1_slope, *(b[i] for b in boundaries), outliers[i])      \n        df.loc[i, 'fg1_slope_g'] = max(0, -df.loc[i, 'fg1_slope_2'])**0.5\n        df.loc[i, 'fg1_curv_left'] = calc_curv_left(fg1_slope, *(b[i] for b in boundaries), outliers[i])\n        df.loc[i, 'fg1_curv_right'] = calc_curv_right(fg1_slope, *(b[i] for b in boundaries), outliers[i])\n\n        \n        # combinations with slopes\n        df.loc[i, 'slope_rel'] = df.loc[i, 'slope_2'] * df.loc[i, 'average_depth']\n        df.loc[i, 'fg1_slope_T'] = df.loc[i, 'fg1_slope_2'] * star_info.loc[i, 'Ts'] \n        df.loc[i, 'fg1_slope_rel'] = df.loc[i, 'fg1_slope_2'] * df.loc[i, 'fg1_average_depth']\n        df.loc[i, 'fg1_slope_g_rel'] = df.loc[i, 'fg1_slope_g'] * df.loc[i, 'fg1_average_depth']\n        \n        for q in [0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n            df.loc[i, f'slope_q_{q}'] = df.loc[i, 'slope_2'] * df.loc[i, f'q_1_{q}']\n            df.loc[i, f'slope_q_{q}_2'] = df.loc[i, 'slope_2'] * df.loc[i, f'q_2_{q}']\n\n        \n        # other features\n        df.loc[i, 't14'] = upper[i] - lower[i]\n        df.loc[i, 't23'] = mid2[i] - mid1[i]\n        df.loc[i, 'time'] = (mid1[i] - lower[i]) / (upper[i] - lower[i])        \n        df.loc[i, 'P_mul_Rs'] = star_info.loc[i, 'P'] * star_info.loc[i, 'Rs']\n        df.loc[i, 'P_div_Rs'] = star_info.loc[i, 'P'] / star_info.loc[i, 'Rs']\n        \n        step = 5\n        max_rel = 0\n        min_rel = 1\n        meaning = 60 # window size for frequency averagning\n        \n        for j in range(1, signal.shape[-1] - meaning + 1, step):\n            if j <= 80:\n                meaning = 20\n            elif j <= 180:\n                meaning = 30\n            else:\n                meaning = 60\n\n            cur_mean = signal[i, :, j : min(j + meaning, signal.shape[-1])].mean(-1)\n\n            # median filter\n            if not outliers[i]:\n                if j >= 180:\n                    med_kernel = 31\n                else:\n                    med_kernel = 21\n                cur_mean = median_filter(cur_mean, size=med_kernel, mode=\"constant\")\n                           \n            cur_mean = savgol_filter(cur_mean, 11, 1)\n            \n            df.loc[i, f'averaged_{j}_unstable'], df.loc[i, f'mid_{j}_unstable'] = calc_depth_and_detrend(cur_mean.copy(), *(b[i] for b in boundaries), \n                                                                                                            outliers[i],\n                                                                                                            unstable=True)  \n            if not outliers[i]:\n                df.loc[i, f'averaged_{j}_unstable'] = 1 - (1 - df.loc[i, f'averaged_{j}_unstable']) * norm_coef\n  \n            if j in good_waves:\n                df.loc[i, f'averaged_{j}'], df.loc[i, f'mid_{j}'] = calc_depth_and_detrend(cur_mean, *(b[i] for b in boundaries),\n                                                                                              outliers[i],\n                                                                                              fixed_degree=3)\n                if not outliers[i]:\n                    df.loc[i, f'averaged_{j}'] = 1 - (1 - df.loc[i, f'averaged_{j}']) * norm_coef_2\n\n            \n            # percentiles\n            for q in [0.1, 0.15, 0.2]:\n                if j in good_waves and not outliers[i]:\n                    df.loc[i, f'q_w_{j}_{q}'] = calc_perc(cur_mean, mid1[i], mid2[i], q, outliers[i])\n                elif outliers[i] and mid1[i] < mid2[i]:\n                    x_combined = np.concatenate([np.arange(max(lower[i] - buf1, 1)), np.arange(min(upper[i] + buf1, max_len), max_len + 1)], axis=-1)\n                    mid_q = np.quantile(cur_mean[mid1[i] : mid2[i]], q)\n                    df.loc[i, f'q_w_{j}_{q}'] = 1 - mid_q / cur_mean[x_combined].mean()\n                else:\n                    df.loc[i, f'q_w_{j}_{q}'] = 0\n           \n            \n            max_rel = max(max_rel, df.loc[i, f'averaged_{j}_unstable'])\n            min_rel = min(min_rel, df.loc[i, f'averaged_{j}_unstable'])\n\n  \n            # slope combinations\n            df.loc[i, f'averaged_slope_{j}'] = df.loc[i, f'averaged_{j}_unstable'] * df.loc[i, 'slope_2']\n            df.loc[i, f'averaged_slope_g_{j}'] = df.loc[i, f'averaged_{j}_unstable'] * df.loc[i, 'slope_g']\n\n        \n        # large amplitude     \n        if max_rel - min_rel >= 0.005:\n            df.loc[i, 'very_bad'] = True\n\n    \n    df['Rs'] = star_info['Rs']\n    df['Ms'] = star_info['Ms']\n    df['Ts'] = star_info['Ts']\n    df['sma'] = star_info['sma']  \n    df['g'] = np.log10(star_info['Ms'] / (star_info['Rs']**2))\n    df['g_T'] = df['g'] * star_info['Ts']\n    df['big_rs'] = (star_info['Rs'] > np.quantile(star_info['Rs'].values, 0.97))\n    \n    df['outliers'] = outliers\n\n    df = df.fillna(0)\n    \n    return outliers, df","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-11-10T09:30:11.655579Z","iopub.execute_input":"2025-11-10T09:30:11.656109Z","iopub.status.idle":"2025-11-10T09:30:11.670163Z","shell.execute_reply.started":"2025-11-10T09:30:11.656079Z","shell.execute_reply":"2025-11-10T09:30:11.669111Z"}},"outputs":[{"name":"stdout","text":"Writing feature_engineering.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"exec(open('feature_engineering.py', 'r').read())\noutliers, train = feature_engineering(train_star_info, data_train)\noutliers = np.arange(train.shape[0])[outliers]\nlen(outliers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:30:44.200153Z","iopub.execute_input":"2025-11-10T09:30:44.200531Z","iopub.status.idle":"2025-11-10T09:47:08.937031Z","shell.execute_reply.started":"2025-11-10T09:30:44.200505Z","shell.execute_reply":"2025-11-10T09:47:08.936118Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1100/1100 [00:00<00:00, 2501.80it/s]\n100%|██████████| 1100/1100 [16:21<00:00,  1.12it/s]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"61"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\nfrom sklearn.utils.validation import check_is_fitted\n\n\nclass CustomRidge(BaseEstimator):\n    \"\"\"\n    Provides two models: main model for normal cases and outlier-specific model\n    \"\"\"\n    def __init__(self):\n        self.main = Ridge(alpha=3e-2) \n        self.outliers = Ridge(alpha=3e-1)\n\n        self.main_scaler = RobustScaler()\n        self.outliers_scaler = RobustScaler()\n\n\n    def fit(self, X, y):\n        groups = X['outliers']\n        X = X.drop(columns=['outliers'])\n\n        main_mask = (groups == 0).values\n        main_mask[X.loc[:, 'very_bad'] == True] = 0\n        \n        X_main = self.main_scaler.fit_transform(X[main_mask])\n\n        self.main.fit(self.main_scaler.transform(X[main_mask]), y[main_mask])\n        self.outliers.fit(self.outliers_scaler.fit_transform(X), y)     \n        self.pred_shape = y.shape[-1]\n\n        return self\n\n    def predict(self, X):\n        groups = X['outliers']\n        X = X.drop(columns=['outliers'])\n        \n        predictions = np.zeros((X.shape[0], self.pred_shape))\n\n        main_mask = (groups == 0).values\n        if main_mask.sum():\n            predictions[main_mask] = self.main.predict(self.main_scaler.transform(X[main_mask]))                                                 \n        if (~main_mask).sum():\n            predictions[~main_mask] = self.outliers.predict(self.outliers_scaler.transform(X[~main_mask]))\n        \n        return predictions\n\n\nmodel = CustomRidge()\n\noof_pred = cross_val_predict(model, train, train_labels.values, cv=100)\n\nprint(f\"# R2 score: {r2_score(train_labels, oof_pred):.3f}\")\n\nsigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\n  \nprint(f\"# Root mean squared error: {sigma_pred:.6f}\")\n\ncol = 1\nplt.scatter(oof_pred[:,col], train_labels.iloc[:,col], s=15, c='lightgreen')\nplt.gca().set_aspect('equal')\nplt.xlabel('y_pred')\nplt.ylabel('y_true')\nplt.title('Comparing y_true and y_pred')\nplt.show()\n\n# clipping\noof_pred = np.maximum(oof_pred, 0.003)\noof_pred = np.minimum(oof_pred, 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:46:28.038345Z","iopub.execute_input":"2025-11-08T21:46:28.039132Z","iopub.status.idle":"2025-11-08T21:47:24.271075Z","shell.execute_reply.started":"2025-11-08T21:46:28.039108Z","shell.execute_reply":"2025-11-08T21:47:24.270495Z"}},"outputs":[{"name":"stdout","text":"# R2 score: 0.999\n# Root mean squared error: 0.000345\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"class SigmaPredictor:\n    \"\"\"\n    Class for sigma predicting\n    \"\"\"\n    def __init__(self):\n        self.sigmas = {}\n        \n    def fit(self, y_pred, y_true, outliers, very_bad):        \n        outliers = [i for i in outliers if i not in very_bad]\n\n        self.sigmas['outliers'] = self._calc(y_pred[outliers], y_true[outliers]) * 5\n\n        main = self._del_outliers(np.ones(len(y_pred), dtype=bool), outliers + list(very_bad))\n        self.sigmas['main'] = self._calc(y_pred[main], y_true[main])\n\n        print({ k: v.mean() for k, v in self.sigmas.items() })\n\n    def predict(self, sigma_pred, y_pred, outliers, very_bad, bootstrap_preds=None):\n        if len(outliers) > 0:\n            sigma_pred[outliers] = self.sigmas['outliers']\n\n        main = self._del_outliers(np.ones(len(y_pred), dtype=bool), outliers)\n        if main.sum() > 0:\n            sigma_pred[main] = self.sigmas['main']\n\n        W1 = 0.75\n        W2 = 1.0 - W1\n        \n        sigma_pred[main, :] = bootstrap_preds[main, :] * W1 + sigma_pred[main, :] * W2\n        sigma_pred[outliers] = bootstrap_preds[outliers] * 1.5\n\n        sigma_pred[very_bad] = 0.003 \n        for i in very_bad:\n            if i in outliers:\n                continue\n            sigma_pred[i, :] = 0.5 * bootstrap_preds[i, :] + 0.5 * sigma_pred[i, :]\n\n        return sigma_pred\n        \n\n    def _calc(self, y_pred, y_true): # calculate rmse for each frequency\n        sigmas = []\n        for i in range(y_pred.shape[1]):\n            sigmas.append(mean_squared_error(y_pred[:, i], y_true[:, i], squared=False))\n        return np.array(sigmas)\n\n    def _del_outliers(self, mask, outliers):\n        for i in range(len(mask)):\n            if i in outliers:\n                mask[i] = False\n        return mask                         \n\n\ndef postprocessing(pred_array, index, sigma_pred, sigma_predictor, outliers, very_bad, bootstrap_preds=None, column_names=None):\n    \"\"\"\n    Creates a submission DataFrame with mean predictions and uncertainties.\n\n    Parameters:\n    - pred_array: ndarray of shape (n_samples, 283)\n    - index: pandas.Index of length n_samples\n    - sigma_pred: float or ndarray of shape (n_samples, 283)\n    - column_names: list of wavelength column names (optional)\n\n    Returns:\n    - df: DataFrame of shape (n_samples, 566)\n    \"\"\"\n    n_samples, n_waves = pred_array.shape\n\n    if column_names is None:\n        column_names = [f\"wl_{i+1}\" for i in range(n_waves)]\n    \n    sigma_pred = sigma_predictor.predict(np.zeros_like(pred_array), pred_array, outliers, very_bad, bootstrap_preds=bootstrap_preds)\n\n    # Safety check\n    assert sigma_pred.shape == pred_array.shape, \"sigma_pred must match shape of pred_array\"\n    assert len(index) == n_samples, \"Index length must match number of rows\"\n\n    df_mean = pd.DataFrame(pred_array.clip(0, None), index=index, columns=column_names)\n    df_sigma = pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i+1}\" for i in range(n_waves)])\n\n    return pd.concat([df_mean, df_sigma], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:47:24.272056Z","iopub.execute_input":"2025-11-08T21:47:24.272847Z","iopub.status.idle":"2025-11-08T21:47:24.283570Z","shell.execute_reply.started":"2025-11-08T21:47:24.272820Z","shell.execute_reply":"2025-11-08T21:47:24.282912Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model.fit(train, train_labels)\n\nsigma_predictor = SigmaPredictor()\nvery_bad = np.arange(train_labels.shape[0])[train['very_bad'].values == True]\nsigma_predictor.fit(oof_pred, train_labels.values, outliers, very_bad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:47:50.399997Z","iopub.execute_input":"2025-11-08T21:47:50.400306Z","iopub.status.idle":"2025-11-08T21:47:51.051450Z","shell.execute_reply.started":"2025-11-08T21:47:50.400284Z","shell.execute_reply":"2025-11-08T21:47:51.049898Z"}},"outputs":[{"name":"stdout","text":"{'outliers': 0.0026830860256072528, 'main': 8.155947694561344e-05}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def bootstrap_uncertainty_inference( \n    X_train,\n    y_train,\n    X_test,\n    n_bootstraps = 100, \n    random_state = 42,\n):\n    \"\"\"\n    Sigma estimation via bootstrapping\n    \"\"\"\n    if random_state is not None:\n        np.random.seed(random_state)\n    \n    y_train_values = y_train\n        \n    n_test_samples = X_test.shape[0]\n    n_targets = y_train_values.shape[1]\n    \n    predictions = np.full((n_test_samples, n_targets, n_bootstraps), np.nan)\n    \n    bootstrap_iter = range(n_bootstraps)\n    bootstrap_iter = tqdm(bootstrap_iter, desc=\"bootstrap interations\")\n    \n    for b in bootstrap_iter:\n        bootstrap_indices = np.random.choice(\n            len(X_train), size=len(X_train), replace=True\n        )\n        \n        X_bootstrap = X_train.iloc[bootstrap_indices].reset_index(drop=True)\n        y_bootstrap = y_train_values.iloc[bootstrap_indices].reset_index(drop=True)\n        \n        model_bootstrap = CustomRidge()\n        model_bootstrap.fit(X_bootstrap, y_bootstrap)\n        \n        y_pred = model_bootstrap.predict(X_test)   \n        predictions[:, :, b] = y_pred\n     \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:47:57.467176Z","iopub.execute_input":"2025-11-08T21:47:57.467722Z","iopub.status.idle":"2025-11-08T21:47:57.473291Z","shell.execute_reply.started":"2025-11-08T21:47:57.467701Z","shell.execute_reply":"2025-11-08T21:47:57.472493Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import pickle\nimport gc\n\n\ntest_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/test_star_info.csv', index_col='planet_id')\nsample_submission = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/sample_submission.csv', index_col='planet_id')\nwavelengths = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/wavelengths.csv')\ntest_star_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2025/test_star_info.csv')\n\ndel data_train\n\ngc.collect()\nos.environ[\"PREPROCESS_MODE\"] = \"test\"\n\n!python preprocess.py\n!rm -rf *AIRS-CH0_signal*\n\ndata_test = np.load(f\"signal_{VERSION}.npy\")\n\noutliers, test_features = feature_engineering(test_star_info, data_test)\noutliers = np.arange(test_features.shape[0])[outliers]\nvery_bad = np.arange(test_features.shape[0])[test_features['very_bad'].values == True]\n\ntest_pred = model.predict(test_features)\n\nboot_pred = bootstrap_uncertainty_inference(train, train_labels, test_features, n_bootstraps=1000)\ntest_bootstrap_preds = boot_pred.std(-1) * 2.75\n\ntest_pred = np.maximum(test_pred, 0.003)\ntest_pred = np.minimum(test_pred, 0.1)\n\nprint('sigma', sigma_pred)\n\n\ndef postprocessing(pred_array, index, sigma_pred, sigma_predictor, outliers, very_bad, bootstrap_preds=None, column_names=None):\n    \"\"\"\n    Convert predictions and uncertainty into final submission DataFrame\n    \"\"\"\n\n    sigma_array = sigma_predictor.predict(np.zeros_like(pred_array), pred_array, outliers, very_bad, bootstrap_preds=bootstrap_preds)\n\n    df_pred = pd.DataFrame(pred_array.clip(0, None), index=index, columns=column_names)\n    df_sigma = pd.DataFrame(sigma_array, index=index, columns=[f\"sigma_{i}\" for i in range(1, len(column_names)+1)])\n    return pd.concat([df_pred, df_sigma], axis=1)\n\n\nsubmission_df = postprocessing(\n    pred_array=test_pred,\n    index=sample_submission.index,\n    sigma_pred=sigma_pred,\n    sigma_predictor=sigma_predictor,\n    column_names=wavelengths.columns,\n    bootstrap_preds=test_bootstrap_preds,\n    outliers=outliers,\n    very_bad=very_bad\n)\n\nsubmission_df.to_csv('submission.csv')\n!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:48:05.639847Z","iopub.execute_input":"2025-11-08T21:48:05.640425Z","iopub.status.idle":"2025-11-08T21:55:28.236958Z","shell.execute_reply.started":"2025-11-08T21:48:05.640400Z","shell.execute_reply":"2025-11-08T21:55:28.236207Z"}},"outputs":[{"name":"stdout","text":"device :  cuda:0\n  0%|                                                     | 0/1 [00:00<?, ?it/s]device :  cuda:0\ndevice :  cuda:0\ndevice :  cuda:0\ndevice :  cuda:0\n100%|█████████████████████████████████████████████| 1/1 [00:11<00:00, 11.95s/it]\nProcessing complete!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 591.75it/s]\n100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\nbootstrap interations: 100%|██████████| 1000/1000 [07:06<00:00,  2.35it/s]","output_type":"stream"},{"name":"stdout","text":"sigma 0.0003446284042227292\nplanet_id,wl_1,wl_2,wl_3,wl_4,wl_5,wl_6,wl_7,wl_8,wl_9,wl_10,wl_11,wl_12,wl_13,wl_14,wl_15,wl_16,wl_17,wl_18,wl_19,wl_20,wl_21,wl_22,wl_23,wl_24,wl_25,wl_26,wl_27,wl_28,wl_29,wl_30,wl_31,wl_32,wl_33,wl_34,wl_35,wl_36,wl_37,wl_38,wl_39,wl_40,wl_41,wl_42,wl_43,wl_44,wl_45,wl_46,wl_47,wl_48,wl_49,wl_50,wl_51,wl_52,wl_53,wl_54,wl_55,wl_56,wl_57,wl_58,wl_59,wl_60,wl_61,wl_62,wl_63,wl_64,wl_65,wl_66,wl_67,wl_68,wl_69,wl_70,wl_71,wl_72,wl_73,wl_74,wl_75,wl_76,wl_77,wl_78,wl_79,wl_80,wl_81,wl_82,wl_83,wl_84,wl_85,wl_86,wl_87,wl_88,wl_89,wl_90,wl_91,wl_92,wl_93,wl_94,wl_95,wl_96,wl_97,wl_98,wl_99,wl_100,wl_101,wl_102,wl_103,wl_104,wl_105,wl_106,wl_107,wl_108,wl_109,wl_110,wl_111,wl_112,wl_113,wl_114,wl_115,wl_116,wl_117,wl_118,wl_119,wl_120,wl_121,wl_122,wl_123,wl_124,wl_125,wl_126,wl_127,wl_128,wl_129,wl_130,wl_131,wl_132,wl_133,wl_134,wl_135,wl_136,wl_137,wl_138,wl_139,wl_140,wl_141,wl_142,wl_143,wl_144,wl_145,wl_146,wl_147,wl_148,wl_149,wl_150,wl_151,wl_152,wl_153,wl_154,wl_155,wl_156,wl_157,wl_158,wl_159,wl_160,wl_161,wl_162,wl_163,wl_164,wl_165,wl_166,wl_167,wl_168,wl_169,wl_170,wl_171,wl_172,wl_173,wl_174,wl_175,wl_176,wl_177,wl_178,wl_179,wl_180,wl_181,wl_182,wl_183,wl_184,wl_185,wl_186,wl_187,wl_188,wl_189,wl_190,wl_191,wl_192,wl_193,wl_194,wl_195,wl_196,wl_197,wl_198,wl_199,wl_200,wl_201,wl_202,wl_203,wl_204,wl_205,wl_206,wl_207,wl_208,wl_209,wl_210,wl_211,wl_212,wl_213,wl_214,wl_215,wl_216,wl_217,wl_218,wl_219,wl_220,wl_221,wl_222,wl_223,wl_224,wl_225,wl_226,wl_227,wl_228,wl_229,wl_230,wl_231,wl_232,wl_233,wl_234,wl_235,wl_236,wl_237,wl_238,wl_239,wl_240,wl_241,wl_242,wl_243,wl_244,wl_245,wl_246,wl_247,wl_248,wl_249,wl_250,wl_251,wl_252,wl_253,wl_254,wl_255,wl_256,wl_257,wl_258,wl_259,wl_260,wl_261,wl_262,wl_263,wl_264,wl_265,wl_266,wl_267,wl_268,wl_269,wl_270,wl_271,wl_272,wl_273,wl_274,wl_275,wl_276,wl_277,wl_278,wl_279,wl_280,wl_281,wl_282,wl_283,sigma_1,sigma_2,sigma_3,sigma_4,sigma_5,sigma_6,sigma_7,sigma_8,sigma_9,sigma_10,sigma_11,sigma_12,sigma_13,sigma_14,sigma_15,sigma_16,sigma_17,sigma_18,sigma_19,sigma_20,sigma_21,sigma_22,sigma_23,sigma_24,sigma_25,sigma_26,sigma_27,sigma_28,sigma_29,sigma_30,sigma_31,sigma_32,sigma_33,sigma_34,sigma_35,sigma_36,sigma_37,sigma_38,sigma_39,sigma_40,sigma_41,sigma_42,sigma_43,sigma_44,sigma_45,sigma_46,sigma_47,sigma_48,sigma_49,sigma_50,sigma_51,sigma_52,sigma_53,sigma_54,sigma_55,sigma_56,sigma_57,sigma_58,sigma_59,sigma_60,sigma_61,sigma_62,sigma_63,sigma_64,sigma_65,sigma_66,sigma_67,sigma_68,sigma_69,sigma_70,sigma_71,sigma_72,sigma_73,sigma_74,sigma_75,sigma_76,sigma_77,sigma_78,sigma_79,sigma_80,sigma_81,sigma_82,sigma_83,sigma_84,sigma_85,sigma_86,sigma_87,sigma_88,sigma_89,sigma_90,sigma_91,sigma_92,sigma_93,sigma_94,sigma_95,sigma_96,sigma_97,sigma_98,sigma_99,sigma_100,sigma_101,sigma_102,sigma_103,sigma_104,sigma_105,sigma_106,sigma_107,sigma_108,sigma_109,sigma_110,sigma_111,sigma_112,sigma_113,sigma_114,sigma_115,sigma_116,sigma_117,sigma_118,sigma_119,sigma_120,sigma_121,sigma_122,sigma_123,sigma_124,sigma_125,sigma_126,sigma_127,sigma_128,sigma_129,sigma_130,sigma_131,sigma_132,sigma_133,sigma_134,sigma_135,sigma_136,sigma_137,sigma_138,sigma_139,sigma_140,sigma_141,sigma_142,sigma_143,sigma_144,sigma_145,sigma_146,sigma_147,sigma_148,sigma_149,sigma_150,sigma_151,sigma_152,sigma_153,sigma_154,sigma_155,sigma_156,sigma_157,sigma_158,sigma_159,sigma_160,sigma_161,sigma_162,sigma_163,sigma_164,sigma_165,sigma_166,sigma_167,sigma_168,sigma_169,sigma_170,sigma_171,sigma_172,sigma_173,sigma_174,sigma_175,sigma_176,sigma_177,sigma_178,sigma_179,sigma_180,sigma_181,sigma_182,sigma_183,sigma_184,sigma_185,sigma_186,sigma_187,sigma_188,sigma_189,sigma_190,sigma_191,sigma_192,sigma_193,sigma_194,sigma_195,sigma_196,sigma_197,sigma_198,sigma_199,sigma_200,sigma_201,sigma_202,sigma_203,sigma_204,sigma_205,sigma_206,sigma_207,sigma_208,sigma_209,sigma_210,sigma_211,sigma_212,sigma_213,sigma_214,sigma_215,sigma_216,sigma_217,sigma_218,sigma_219,sigma_220,sigma_221,sigma_222,sigma_223,sigma_224,sigma_225,sigma_226,sigma_227,sigma_228,sigma_229,sigma_230,sigma_231,sigma_232,sigma_233,sigma_234,sigma_235,sigma_236,sigma_237,sigma_238,sigma_239,sigma_240,sigma_241,sigma_242,sigma_243,sigma_244,sigma_245,sigma_246,sigma_247,sigma_248,sigma_249,sigma_250,sigma_251,sigma_252,sigma_253,sigma_254,sigma_255,sigma_256,sigma_257,sigma_258,sigma_259,sigma_260,sigma_261,sigma_262,sigma_263,sigma_264,sigma_265,sigma_266,sigma_267,sigma_268,sigma_269,sigma_270,sigma_271,sigma_272,sigma_273,sigma_274,sigma_275,sigma_276,sigma_277,sigma_278,sigma_279,sigma_280,sigma_281,sigma_282,sigma_283\n1103775,0.015489698939218886,0.015894007176240475,0.015890814636674185,0.01588958789771034,0.015888878980327033,0.015886427725787782,0.015882289928095775,0.01587844508746556,0.01587593710536954,0.015873573549642684,0.015869805185441677,0.015864869900756667,0.015860102368777405,0.015855838439313364,0.0158514389591591,0.015846941864203736,0.015843476697284503,0.015841530787602802,0.01584001843637421,0.01583790957990191,0.015835679264915397,0.015834666096404645,0.015835612839396957,0.015837833217508077,0.01583995848625957,0.01584116198738974,0.015841589919778964,0.015841824606612622,0.015842152640853382,0.015842380512882545,0.015842468408064407,0.015843156556041897,0.01584534879657785,0.015848828447538762,0.01585190247666415,0.015852973894045316,0.015852411480945208,0.015852440354849003,0.015855150629410453,0.015860564486789595,0.01586688206075554,0.0158725383859529,0.015877112865171877,0.01588023126846427,0.015880805311710298,0.015878513943300764,0.015875341883326108,0.015874345916600925,0.01587713510554002,0.015882712940539955,0.01588874138551369,0.015893365031526267,0.015895980869153312,0.0158968548294926,0.015896686756524683,0.015896286898613013,0.01589666976368509,0.015898608702570455,0.015901766194206864,0.015905206618914126,0.015908531901470315,0.015912079694281416,0.0159162569536678,0.015920980437346775,0.015925813353380752,0.015929974655791223,0.01593273003071649,0.015933822741832783,0.015933590111510534,0.01593253408792878,0.01593209075300691,0.015934441258786295,0.015940542660626295,0.015947654950103612,0.015951274726339598,0.015951023965022532,0.015950607510020642,0.01595183120840678,0.01595209363956144,0.01594913502570251,0.015944726688270072,0.01594138612569035,0.01593787611368063,0.015932497723145107,0.015927195463206166,0.015926402746321906,0.01593106701458076,0.0159368819630853,0.015938500739927516,0.015936391097505068,0.015935637821133018,0.015938289770601112,0.015939395937422975,0.015934196412688353,0.01592588220053412,0.01592141068383102,0.01592195784954076,0.015922022155373184,0.01591836976938141,0.01591491443553946,0.01591723804562917,0.015924628349507634,0.015930121267862973,0.015928598852046155,0.015923098327072366,0.01592216469960039,0.01592926936452042,0.01593796798514976,0.015939146943361668,0.01593180246652709,0.01592187601158746,0.015914222018223595,0.01590923022845634,0.01590559874018409,0.0159026997932212,0.015901369153291572,0.015902627263833374,0.015906268388798942,0.015911547246054068,0.015918225974998226,0.015924799085437414,0.015928399224837613,0.015928210233626817,0.015927624984473008,0.015930845702594364,0.015938720291677887,0.015948708604714604,0.01595786960233004,0.01596479256784287,0.0159694049320586,0.01597295597324196,0.015977512013767133,0.015984761588975688,0.015994853573907883,0.01600515051056737,0.016010663514804173,0.016007553857285573,0.015997343071512717,0.015985726830861732,0.01597568731042991,0.01596600961467639,0.01595739762822107,0.015952482874513785,0.015949072335540826,0.015944210989586587,0.01594115890224989,0.015941339289993528,0.015939489824833224,0.01593426940417301,0.015929629707440978,0.015925777151208402,0.015921552071293733,0.015918933781601387,0.015917757991081145,0.015915411520007253,0.015912084275161893,0.015909259180568056,0.015907151975610906,0.015905853615653512,0.015903707817152682,0.01589887244969626,0.015894437368124903,0.015894059126076616,0.015894342749628712,0.015889506988127095,0.015880375409914053,0.015872752697442524,0.015869754360982032,0.01586909684554503,0.015866054386774766,0.015859679936721882,0.01585461371271448,0.0158542270961246,0.015856165691921102,0.015855870476150793,0.015851900966381068,0.015848767438182504,0.015852551357987153,0.015861469181238087,0.015867474019258237,0.01586788383976772,0.01586585441702965,0.01586152066293591,0.015854427283490364,0.01584889118972634,0.01584720531571933,0.015844975252713854,0.015840258754089932,0.01583818116420383,0.0158406856968617,0.015842930503608188,0.015843742022035097,0.015847165297727468,0.01585404606524654,0.01586109059260316,0.015864469055656336,0.015862114139377756,0.01585670980317941,0.015851256495399903,0.01584656509156225,0.015844348154412245,0.01584615200085844,0.015851055120720742,0.01585492773811283,0.01585490010226616,0.015853460187804556,0.015854229627820255,0.015856558592533498,0.01585732334941331,0.015854976883012295,0.015850040358218007,0.01584657087290502,0.01584791661625963,0.015850575908214246,0.015850627411017438,0.015849254889395224,0.01584797694433826,0.01584668387868666,0.015845699361834692,0.015845474816812026,0.01584568013147499,0.015846146060023065,0.015846533137757197,0.015845924643488718,0.01584504588698523,0.015844703512042473,0.015845702117268844,0.015847882423025587,0.015848314992977033,0.015846725174442557,0.015846558016457006,0.01584907014912724,0.015852614423962755,0.015854288325182535,0.015852859578404595,0.01585008344964374,0.015849734600481256,0.01585238088648905,0.015856112605017108,0.015859969403922026,0.01586153788124876,0.015861613428553027,0.015861820793834483,0.015861708430793486,0.01586445041747278,0.01586926496527181,0.015871312709128425,0.015869544539917842,0.015868906500438925,0.01587316045945262,0.01587595890830906,0.015874323687463728,0.015875087979134575,0.015877542811485144,0.015877009587663846,0.01587918744397164,0.015882394605807898,0.015881970452708238,0.015883170792543685,0.015885019866917923,0.01588702987094807,0.015890095256955613,0.01588878295128627,0.015887555978882268,0.015889097715261633,0.01588437681893299,0.015877182550666256,0.01587488800268393,0.01587493486500488,0.015875019229266773,0.015872141291717903,0.015869141995958735,0.01586958573528724,0.015870982923207093,0.015870733514915324,0.015868318070571652,0.015867952558559908,0.015871917096809664,0.015873406538504733,0.01587319112912133,0.015873012559345517,0.01586885255680453,0.01586722539929333,0.00011182593475024503,5.801791487980878e-05,5.903326632421609e-05,5.9439593975515973e-05,5.913454518332558e-05,5.787967883795161e-05,5.637442547151804e-05,5.5881717807935354e-05,5.651630802848756e-05,5.732375224473953e-05,5.753450455707287e-05,5.7414053227482185e-05,5.7600793012673646e-05,5.792370355434237e-05,5.7845842061514754e-05,5.7338603324031744e-05,5.677591582956487e-05,5.63062494379224e-05,5.582380026477183e-05,5.520603522173592e-05,5.4448734104439866e-05,5.3651573167483383e-05,5.305976905267252e-05,5.281673657372901e-05,5.284547316242271e-05,5.3233789604747604e-05,5.3982688390885215e-05,5.4154739113875975e-05,5.270132620424542e-05,5.033672453813115e-05,4.866074127392242e-05,4.806706916880082e-05,4.854786458547657e-05,4.976784902818986e-05,5.0431747859607364e-05,5.0135753624316415e-05,4.9884776625472305e-05,5.048430888177137e-05,5.164359337667133e-05,5.298700877323104e-05,5.4509911296606606e-05,5.6152938965919354e-05,5.756491890061679e-05,5.7818681805370945e-05,5.614129393223717e-05,5.333009258115463e-05,5.132740576728516e-05,5.0858535623332464e-05,5.124387041479751e-05,5.188130570469593e-05,5.2317973011371786e-05,5.198278172325239e-05,5.074028896271062e-05,4.944587290984231e-05,4.885175271336956e-05,4.8530109132027374e-05,4.815048561279069e-05,4.7991966847457715e-05,4.782812337160714e-05,4.754344043681835e-05,4.78514910053822e-05,4.888359136068096e-05,4.98794521710837e-05,5.050604895361066e-05,5.053902100534449e-05,5.062561745616149e-05,5.2462223626860966e-05,5.5136427335382746e-05,5.560274773430339e-05,5.308556034317054e-05,5.1559274206990005e-05,5.2900994044729924e-05,5.3390234146237205e-05,5.3365908548209405e-05,5.3366121840366806e-05,5.304225634161753e-05,5.300953315589589e-05,5.251698499537071e-05,5.163896770776297e-05,5.053970639103014e-05,4.9504338990109704e-05,4.929293390163932e-05,4.973172687025753e-05,5.00839036711505e-05,4.971349729769097e-05,4.9477970624730825e-05,5.018741381654487e-05,5.181057624797685e-05,5.3595721135347825e-05,5.480897101376191e-05,5.645895803899706e-05,5.953744611082159e-05,6.193633396182369e-05,6.243276980191727e-05,6.175329352327676e-05,5.98601691448206e-05,5.776313514359078e-05,5.6625978214146466e-05,5.5982146545075696e-05,5.604391118312275e-05,5.7837888290844224e-05,6.0584422763040004e-05,6.0618147874904794e-05,5.7657553668989623e-05,5.5441881936368526e-05,5.455492982798465e-05,5.542551264698999e-05,5.916158944591615e-05,5.95615339902354e-05,5.6095489280096565e-05,5.354793986130455e-05,5.2513540995482655e-05,5.2471043652405766e-05,5.277037434602553e-05,5.294400441349032e-05,5.228111795593366e-05,5.1551655088462976e-05,5.2082718350980744e-05,5.357373734582439e-05,5.508586699953882e-05,5.7514858196099266e-05,6.006516627975143e-05,5.998303346808517e-05,5.853080674102122e-05,5.9457194177828896e-05,6.090388968712416e-05,6.01340521801918e-05,5.93082836593992e-05,6.001983235136812e-05,6.180133822110255e-05,6.320516926840862e-05,6.439427376563025e-05,6.894238242746665e-05,7.546745203523123e-05,7.725152170400006e-05,7.840881984998459e-05,7.804700300970791e-05,7.461007146892802e-05,7.298404227203004e-05,7.170248647139829e-05,6.873214203390577e-05,6.701632194368332e-05,6.75417154455261e-05,6.711081236570316e-05,6.557374197709545e-05,6.523067333795164e-05,6.519264806996005e-05,6.576082473446022e-05,6.654557838506797e-05,6.717464867167542e-05,6.625291565772242e-05,6.425461868438942e-05,6.394288938237541e-05,6.49958309671215e-05,6.507854880846055e-05,6.448317191097192e-05,6.414555753102957e-05,6.381938571996288e-05,6.250731471462516e-05,6.077266924066783e-05,5.967061923400071e-05,5.932535529325759e-05,5.8836959119998406e-05,5.7810150407711246e-05,5.691522523557244e-05,5.725339569281433e-05,5.6396934251270415e-05,5.492947748876081e-05,5.4669215473915364e-05,5.355402506328684e-05,5.232456474680639e-05,5.1668973579092576e-05,5.1091373199406724e-05,5.0486886481050856e-05,5.001929529886724e-05,5.013339114452125e-05,5.09182818624011e-05,5.046781453641007e-05,5.094999540793199e-05,5.4468455645658554e-05,6.294788738961184e-05,7.18143100637739e-05,7.453763897457102e-05,7.311659314275306e-05,7.036426793586458e-05,6.709719913328831e-05,6.379372789660596e-05,6.147737396053324e-05,5.950123576819418e-05,5.644765988229778e-05,5.483328768972611e-05,5.4031133559135734e-05,5.317718888133253e-05,5.316808120726443e-05,5.3648155225605954e-05,5.411724378156316e-05,5.4398935775575514e-05,5.464463247802269e-05,5.563476097596416e-05,5.674880570041392e-05,5.73455752405535e-05,5.723460412597586e-05,5.773449974948978e-05,5.892234903526983e-05,5.903671613202103e-05,5.9388947571210144e-05,6.050904603291441e-05,6.0621716570404014e-05,5.980541933714758e-05,5.916273528885957e-05,5.9433104093936567e-05,5.942277962555281e-05,5.8236535838780345e-05,5.745783421046066e-05,5.831955901270053e-05,6.07283190240372e-05,6.2947410521017e-05,6.327792487193002e-05,6.228219135089842e-05,6.27834151794907e-05,6.400274641837034e-05,6.648181414705694e-05,6.688240568176711e-05,6.530646001869202e-05,6.397885057100579e-05,6.193379552574485e-05,5.9496349964279345e-05,5.824984766735124e-05,5.716676863277521e-05,5.5663451789495645e-05,5.483637411917215e-05,5.456513905243587e-05,5.4884808255391196e-05,5.588879862892776e-05,5.5913340584137924e-05,5.5927250058675164e-05,5.5838251294311345e-05,5.496390461557007e-05,5.455359580501801e-05,5.503397567270161e-05,5.559523846817672e-05,5.536524903842603e-05,5.601923489249842e-05,5.801380685432745e-05,5.908238390837912e-05,5.9151349387983595e-05,6.064288574203608e-05,6.0697546943587865e-05,5.8722099705136127e-05,5.806119320000997e-05,5.8450751587629804e-05,5.7853771572815435e-05,5.7827546780738044e-05,6.034089892533857e-05,6.233574526257697e-05,6.220540166761172e-05,6.185518830560017e-05,6.223572309093315e-05,6.286920601160203e-05,6.341735486392277e-05,6.396072587182031e-05,6.390791721084692e-05,6.366354885637535e-05,6.321293301411848e-05,6.238783024687555e-05,6.315328575601615e-05,6.41844373967944e-05,6.138784326156763e-05,5.9759675580817636e-05,6.0995184689211395e-05,6.222349304949101e-05,6.307147427966187e-05,6.643787762063143e-05,6.937876002626215e-05,6.789434934252137e-05,6.707985838201808e-05,6.727907378821063e-05,6.813135897944743e-05,6.820108193891234e-05,6.722159594537153e-05,6.736155082153038e-05,6.939226296075963e-05,6.992597032762438e-05\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"import joblib\nimport os\n\n# after training\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\njoblib.dump(model, \"/kaggle/working/models/custom_ridge.pkl\")\n\nprint(\"✅ Model saved at /kaggle/working/models/custom_ridge.pkl\")\n\n\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\njoblib.dump(sigma_predictor, \"/kaggle/working/models/SigmaPredictor.pkl\")\n\nprint(\"✅ sigma_predictor saved at /kaggle/working/models/SigmaPredictor.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T21:55:28.250669Z","iopub.execute_input":"2025-11-08T21:55:28.250844Z","iopub.status.idle":"2025-11-08T21:55:28.268177Z","shell.execute_reply.started":"2025-11-08T21:55:28.250830Z","shell.execute_reply":"2025-11-08T21:55:28.267423Z"}},"outputs":[{"name":"stdout","text":"✅ Model saved at /kaggle/working/models/custom_ridge.pkl\n✅ Model saved at /kaggle/working/models/SigmaPredictor.pkl\n","output_type":"stream"}],"execution_count":32}]}